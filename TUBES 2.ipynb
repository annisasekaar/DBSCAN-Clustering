{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cluster import DBSCAN\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DBSCAN_mn :\n",
    "    # initialize\n",
    "    def __init__(self, eps, min_samples) :\n",
    "        self.eps = eps\n",
    "        self.min_samples = min_samples\n",
    "        self.visit = []\n",
    "        self.clusters = []\n",
    "        self.list_of_cluster = []\n",
    "        self.noise = []\n",
    "        self.core = [] # for predict\n",
    "        self.dataset = []\n",
    "        \n",
    "    def fit(self, dataset) : # list\n",
    "        self.visit = dataset[:].tolist() # create label for visited data\n",
    "        self.dataset = dataset[:].tolist()\n",
    "        C = -1 # create cluster\n",
    "        for data in self.dataset :\n",
    "            if data in self.visit :\n",
    "                self.visit.remove(data)\n",
    "                # find all neighbor for sample data\n",
    "                data_neighbor = self.find_neighbors(data)\n",
    "                if len(data_neighbor) < self.min_samples : self.noise.append(data)\n",
    "                else :\n",
    "                    C += 1\n",
    "                    self.expand_cluster(data, data_neighbor, C)\n",
    "        self.create_cluster()\n",
    "                    \n",
    "    def expand_cluster(self, sample, sample_neighbor, C) :\n",
    "        # first delete clustered element before because it's not core\n",
    "        for inst in self.clusters :\n",
    "                if sample in inst : self.clusters[self.clusters.index(inst)].remove(sample)\n",
    "        self.clusters.insert(C, [sample])\n",
    "        self.core.append(sample)\n",
    "        \n",
    "        for data in sample_neighbor :\n",
    "            if data in self.visit : # is not visited yet\n",
    "                self.visit.remove(data)\n",
    "                data_neighbor = self.find_neighbors(data)\n",
    "                if len(data_neighbor) >= self.min_samples :\n",
    "                    self.core.append(data)\n",
    "                    for elmt in data_neighbor :\n",
    "                        if elmt not in sample_neighbor : sample_neighbor.append(elmt)\n",
    "            cluster = False\n",
    "            for inst in self.clusters :\n",
    "                if data in inst :\n",
    "                    cluster = True\n",
    "                    break\n",
    "            if cluster == False : \n",
    "                self.clusters[C].append(data)\n",
    "                if data in self.noise : self.noise.remove(data)\n",
    "    \n",
    "    def find_neighbors(self, sample) :\n",
    "        neighbor = []\n",
    "        for data in self.dataset :\n",
    "            distance = math.sqrt(sum([(a - b) ** 2 for a, b in zip(sample, data)])) # calculate euclidian distance\n",
    "            if distance <= self.eps : neighbor.append(data)        \n",
    "        return neighbor\n",
    "    \n",
    "    def create_cluster(self) :\n",
    "        for data in self.dataset :\n",
    "            for i in range(len(self.clusters)) :\n",
    "                if data in self.clusters[i] : \n",
    "                    self.list_of_cluster.append(i)\n",
    "            if data in self.noise : \n",
    "                self.list_of_cluster.append(-1)\n",
    "        self.list_of_cluster = np.array(self.list_of_cluster)\n",
    "        \n",
    "    def predict(self, datatest) :\n",
    "        pred = []\n",
    "        for data in datatest.tolist() :\n",
    "            appended = False\n",
    "            for core_ in self.core :\n",
    "                distance = math.sqrt(sum([(a - b) ** 2 for a, b in zip(core_, data)])) # calculate euclidian distance\n",
    "                #print(\"distance between \", data, \" and \", core_, \" is \", distance)\n",
    "                if distance <= self.eps : \n",
    "                    #print(\"it is in cluster \", self.dataset.index(core_))\n",
    "                    pred.append(self.list_of_cluster[self.dataset.index(core_)])\n",
    "                    appended = True\n",
    "                    break\n",
    "            if appended == False : \n",
    "                pred.append(-1)\n",
    "        return np.array(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into test and train, but sort ordinal first to reduce mislabel\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "np.size(X_train,0)\n",
    "X_temp = np.concatenate((X_train, np.array([y_train]).T), axis=1)\n",
    "X_temp = X_temp[X_temp[:, np.size(X,1)-1].argsort()]\n",
    "X_train = np.array([i[:-1] for i in X_temp.tolist()])\n",
    "y_train = np.array([i[-1] for i in X_temp.tolist()]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== minpts : 2 && eps : 0.3 ========\n",
      "WITH SPLIT  135 : 15\n",
      "\n",
      "DBSCAN Clustering from Scratch\n",
      "Confusion Matrix :\n",
      "[[0 0 0 0 0 0]\n",
      " [1 2 0 0 0 0]\n",
      " [6 0 2 0 0 0]\n",
      " [2 0 0 0 1 1]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "Accuracy Score :\n",
      "0.26666666666666666\n",
      "______________________________\n",
      "\n",
      "WITHOUT SPLIT\n",
      "\n",
      "DBSCAN Clustering from scratch\n",
      "Confusion Matrix :\n",
      "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [10 38  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [14  0  0  3  2 14  6  2  4  2  2  1  0  0  0  0  0  0  0  0  0  0]\n",
      " [19  0  0  0  0  0  0  0  0  0  0  6  3  3  2  2  2  2  5  2  2  2]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "Accuracy Score :\n",
      "0.25333333333333335\n",
      "\n",
      "DBSCAN Clustering from sklearn\n",
      "Confusion Matrix :\n",
      "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [10 38  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [14  0  0  3  2 14  6  2  4  2  2  1  0  0  0  0  0  0  0  0  0  0]\n",
      " [19  0  0  0  0  0  0  0  0  0  0  6  3  3  2  2  2  2  5  2  2  2]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "Accuracy Score :\n",
      "0.25333333333333335\n",
      "\n",
      "\n",
      "\n",
      "======== minpts : 2 && eps : 0.7 ========\n",
      "WITH SPLIT  135 : 15\n",
      "\n",
      "DBSCAN Clustering from Scratch\n",
      "Confusion Matrix :\n",
      "[[0 0 0 0]\n",
      " [0 3 0 0]\n",
      " [0 0 8 0]\n",
      " [1 0 3 0]]\n",
      "Accuracy Score :\n",
      "0.7333333333333333\n",
      "______________________________\n",
      "\n",
      "WITHOUT SPLIT\n",
      "\n",
      "DBSCAN Clustering from scratch\n",
      "Confusion Matrix :\n",
      "[[ 0  0  0  0  0]\n",
      " [ 0 50  0  0  0]\n",
      " [ 0  0 50  0  0]\n",
      " [ 1  0 47  0  2]\n",
      " [ 0  0  0  0  0]]\n",
      "Accuracy Score :\n",
      "0.6666666666666666\n",
      "\n",
      "DBSCAN Clustering from sklearn\n",
      "Confusion Matrix :\n",
      "[[ 0  0  0  0]\n",
      " [ 0 50  0  0]\n",
      " [ 0  0 50  0]\n",
      " [ 1  0 47  2]]\n",
      "Accuracy Score :\n",
      "0.68\n",
      "\n",
      "\n",
      "\n",
      "======== minpts : 2 && eps : 3 ========\n",
      "WITH SPLIT  135 : 15\n",
      "\n",
      "DBSCAN Clustering from Scratch\n",
      "Confusion Matrix :\n",
      "[[3 0 0]\n",
      " [8 0 0]\n",
      " [4 0 0]]\n",
      "Accuracy Score :\n",
      "0.2\n",
      "______________________________\n",
      "\n",
      "WITHOUT SPLIT\n",
      "\n",
      "DBSCAN Clustering from scratch\n",
      "Confusion Matrix :\n",
      "[[50  0  0]\n",
      " [50  0  0]\n",
      " [50  0  0]]\n",
      "Accuracy Score :\n",
      "0.3333333333333333\n",
      "\n",
      "DBSCAN Clustering from sklearn\n",
      "Confusion Matrix :\n",
      "[[50  0  0]\n",
      " [50  0  0]\n",
      " [50  0  0]]\n",
      "Accuracy Score :\n",
      "0.3333333333333333\n",
      "\n",
      "\n",
      "\n",
      "======== minpts : 20 && eps : 0.75 ========\n",
      "WITH SPLIT  135 : 15\n",
      "\n",
      "DBSCAN Clustering from Scratch\n",
      "Confusion Matrix :\n",
      "[[0 0 0 0]\n",
      " [0 3 0 0]\n",
      " [1 0 7 0]\n",
      " [1 0 3 0]]\n",
      "Accuracy Score :\n",
      "0.6666666666666666\n",
      "______________________________\n",
      "\n",
      "WITHOUT SPLIT\n",
      "\n",
      "DBSCAN Clustering from scratch\n",
      "Confusion Matrix :\n",
      "[[ 0  0  0  0]\n",
      " [ 0 50  0  0]\n",
      " [ 4  0 46  0]\n",
      " [ 9  0 41  0]]\n",
      "Accuracy Score :\n",
      "0.64\n",
      "\n",
      "DBSCAN Clustering from sklearn\n",
      "Confusion Matrix :\n",
      "[[ 0  0  0  0]\n",
      " [ 0 50  0  0]\n",
      " [ 4  0 46  0]\n",
      " [ 8  0 42  0]]\n",
      "Accuracy Score :\n",
      "0.64\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"======== minpts : 2 && eps : 0.3 ========\")\n",
    "print(\"WITH SPLIT \", len(y_train), \":\", len(y_test))\n",
    "print(\"\\nDBSCAN Clustering from Scratch\")\n",
    "model1_mn = DBSCAN_mn(0.3,2)\n",
    "model1_mn.fit(X_train)\n",
    "y_predict = model1_mn.predict(X_test)\n",
    "print(\"Confusion Matrix :\")\n",
    "print(confusion_matrix(y_test, y_predict))\n",
    "print(\"Accuracy Score :\")\n",
    "print(accuracy_score(y_test, y_predict))\n",
    "\n",
    "print(\"______________________________\")\n",
    "print(\"\\nWITHOUT SPLIT\")\n",
    "print(\"\\nDBSCAN Clustering from scratch\")\n",
    "model1 = DBSCAN_mn(0.3, 2)\n",
    "model1.fit(X)\n",
    "pred1_mn = model1.predict(X)\n",
    "print(\"Confusion Matrix :\")\n",
    "print(confusion_matrix(y, pred1_mn))\n",
    "print(\"Accuracy Score :\")\n",
    "print(accuracy_score(y, pred1_mn))\n",
    "\n",
    "print(\"\\nDBSCAN Clustering from sklearn\")\n",
    "pred1_sk = DBSCAN(eps=0.3, min_samples=2).fit_predict(X)\n",
    "print(\"Confusion Matrix :\")\n",
    "print(confusion_matrix(y, pred1_sk))\n",
    "print(\"Accuracy Score :\")\n",
    "print(accuracy_score(y, pred1_sk))\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "print(\"======== minpts : 2 && eps : 0.7 ========\")\n",
    "print(\"WITH SPLIT \", len(y_train), \":\", len(y_test))\n",
    "print(\"\\nDBSCAN Clustering from Scratch\")\n",
    "model2_mn = DBSCAN_mn(0.7,2)\n",
    "model2_mn.fit(X_train)\n",
    "y_predict2 = model2_mn.predict(X_test)\n",
    "print(\"Confusion Matrix :\")\n",
    "print(confusion_matrix(y_test, y_predict2))\n",
    "print(\"Accuracy Score :\")\n",
    "print(accuracy_score(y_test, y_predict2))\n",
    "\n",
    "print(\"______________________________\")\n",
    "print(\"\\nWITHOUT SPLIT\")\n",
    "print(\"\\nDBSCAN Clustering from scratch\")\n",
    "model2 = DBSCAN_mn(0.7, 2)\n",
    "model2.fit(X)\n",
    "pred2_mn = model2.predict(X)\n",
    "print(\"Confusion Matrix :\")\n",
    "print(confusion_matrix(y, pred2_mn))\n",
    "print(\"Accuracy Score :\")\n",
    "print(accuracy_score(y, pred2_mn))\n",
    "\n",
    "print(\"\\nDBSCAN Clustering from sklearn\")\n",
    "pred2_sk = DBSCAN(eps=0.7, min_samples=2).fit_predict(X)\n",
    "print(\"Confusion Matrix :\")\n",
    "print(confusion_matrix(y, pred2_sk))\n",
    "print(\"Accuracy Score :\")\n",
    "print(accuracy_score(y, pred2_sk))\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "print(\"======== minpts : 2 && eps : 3 ========\")\n",
    "print(\"WITH SPLIT \", len(y_train), \":\", len(y_test))\n",
    "print(\"\\nDBSCAN Clustering from Scratch\")\n",
    "model3_mn = DBSCAN_mn(3,2)\n",
    "model3_mn.fit(X_train)\n",
    "y_predict3 = model3_mn.predict(X_test)\n",
    "print(\"Confusion Matrix :\")\n",
    "print(confusion_matrix(y_test, y_predict3))\n",
    "print(\"Accuracy Score :\")\n",
    "print(accuracy_score(y_test, y_predict3))\n",
    "\n",
    "print(\"______________________________\")\n",
    "print(\"\\nWITHOUT SPLIT\")\n",
    "print(\"\\nDBSCAN Clustering from scratch\")\n",
    "model3 = DBSCAN_mn(3, 2)\n",
    "model3.fit(X)\n",
    "pred3_mn = model3.predict(X)\n",
    "print(\"Confusion Matrix :\")\n",
    "print(confusion_matrix(y, pred3_mn))\n",
    "print(\"Accuracy Score :\")\n",
    "print(accuracy_score(y, pred3_mn))\n",
    "\n",
    "print(\"\\nDBSCAN Clustering from sklearn\")\n",
    "pred3_sk = DBSCAN(eps=3, min_samples=2).fit_predict(X)\n",
    "print(\"Confusion Matrix :\")\n",
    "print(confusion_matrix(y, pred3_sk))\n",
    "print(\"Accuracy Score :\")\n",
    "print(accuracy_score(y, pred3_sk))\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "print(\"======== minpts : 20 && eps : 0.75 ========\")\n",
    "print(\"WITH SPLIT \", len(y_train), \":\", len(y_test))\n",
    "print(\"\\nDBSCAN Clustering from Scratch\")\n",
    "model4_mn = DBSCAN_mn(0.75,20)\n",
    "model4_mn.fit(X_train)\n",
    "y_predict4 = model4_mn.predict(X_test)\n",
    "print(\"Confusion Matrix :\")\n",
    "print(confusion_matrix(y_test, y_predict4))\n",
    "print(\"Accuracy Score :\")\n",
    "print(accuracy_score(y_test, y_predict4))\n",
    "\n",
    "print(\"______________________________\")\n",
    "print(\"\\nWITHOUT SPLIT\")\n",
    "print(\"\\nDBSCAN Clustering from scratch\")\n",
    "model4 = DBSCAN_mn(0.75, 20)\n",
    "model4.fit(X)\n",
    "pred4_mn = model4.predict(X)\n",
    "print(\"Confusion Matrix :\")\n",
    "print(confusion_matrix(y, pred4_mn))\n",
    "print(\"Accuracy Score :\")\n",
    "print(accuracy_score(y, pred4_mn))\n",
    "\n",
    "print(\"\\nDBSCAN Clustering from sklearn\")\n",
    "pred4_sk = DBSCAN(eps=0.75, min_samples=20).fit_predict(X)\n",
    "print(\"Confusion Matrix :\")\n",
    "print(confusion_matrix(y, pred4_sk))\n",
    "print(\"Accuracy Score :\")\n",
    "print(accuracy_score(y, pred4_sk))\n",
    "\n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
